# ğŸ¤– Local Chatbot Experiment with Ollama, Phidata & Streamlit

Welcome to my experimental project where Iâ€™m building a **local AI chatbot** by integrating:

âœ… **Ollama** for running LLMs locally  
âœ… **Phidata** as the orchestration framework  
âœ… **Streamlit** for a simple, interactive frontend

The goal is to explore deploying a fully local chatbot solution without relying on external APIs, ensuring privacy, control, and customization.

---

## ğŸš€ Features

- Run **LLMs locally** using [Ollama](https://ollama.com/)
- Manage pipelines & agents with **Phidata**
- Friendly web UI powered by **Streamlit**
- Easily extensible for new models or workflows
- No cloud dependency (everything runs on your machine)

---

## ğŸ—ï¸ Project Structure


```bash
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ app.py             # Streamlit frontend
â”‚   â”œâ”€â”€ phidata/
â”‚   â”‚   â”œâ”€â”€ phidata_config.py  # Phidata configuration
â”‚   â”‚   â””â”€â”€ chatbot_agent.py   # Bot logic / pipeline
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file